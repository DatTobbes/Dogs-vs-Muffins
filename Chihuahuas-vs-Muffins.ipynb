{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convolutional Neural Network Tutorial\n",
    "\n",
    "Mit diesem Notebook bietet eine erste einfache Einführung in die Verwendung von Convolutional Neural Networks.\n",
    "Es werden alle wichtigen Schritte von durchgeführt und beschrieben die notwendig sind um ein Model zu erstellen, Trainingsdaten zu laden, das Model zu trainieren und anschließend zu bewerten.\n",
    "\n",
    "Es wird ein CNN als binärer Klassifikator trainiert werden um Chihuahuas von Muffins zu unterscheiden. \n",
    "<img src=\"Notebook_Images/full.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitungen\n",
    "\n",
    "    1. Python installieren: https://www.python.org/downloads/\n",
    "    2. Jupyter installiern: http://jupyter.org/install\n",
    "        In commandprompt:\n",
    "        python3 -m pip install --upgrade pip\n",
    "        python3 -m pip install jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Bilder\n",
    "Zunächst müssen die Daten zum Training geladen werden. Die einzelnen Dateien müssen dafür nach Klassen sortiert in Ordner vorhanden sein. <br>\n",
    "* \\Data\n",
    "   * \\Chihuahuas \n",
    "      *  img1.jpg\n",
    "      *  img2.jpg\n",
    "      *  img3.jpg \n",
    "   * \\Muffins\n",
    "       * img1.jpg \n",
    "       * img2.jpg \n",
    "       * img3.jpg \n",
    "\n",
    "Bilddateien aus diesen Ordnern werden geladen, skaliert und ein Array mit entsprechenden Labels erstellt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_height=172\n",
    "image_width= 171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diese Datei ist Teil des Repositorys\n",
    "from dataset import DataLoader\n",
    "#Pfad zu den Ordnern mit den Bildern \n",
    "data_dir = '.\\\\Images\\\\chihuahua-muffin\\\\train'\n",
    "\n",
    "testset= DataLoader()\n",
    "images, labels = testset.load_data(data_dir, image_height,image_width)\n",
    "images, labels = testset.normalizeData(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenset speichern in einer npz-Datei\n",
    "Um die Bilder nicht jedesmal neu laden zu müssen, stellt numpy eine sehr effizente Methode zur Verfügung um große Datenmengen als .npz-Datei zu speichern. Dafür müssen der Methode die Bilder und Labels als Numpy-Array übergeben werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= 'dog-vs-muffins.npz'\n",
    "np.savez_compressed(filename,\n",
    "                    images=images,\n",
    "                    labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der Daten aus einer npz-Datei\n",
    "Die Bilder und Labels können nach öffnen der Datei geladen werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset= np.load('dog-vs-muffins.npz')\n",
    "labels=dataset['labels']\n",
    "images=dataset['images']\n",
    "images= np.concatenate((images[labels ==0][:100], images[labels ==1][:100]) ,axis=0)\n",
    "labels= np.concatenate((labels[labels ==0][:100], labels[labels ==1][:100]) ,axis=0)\n",
    "print('load %d files' %len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anzeigen einiger Testbilder\n",
    "Die Plot-Methode wird in diesem Notebook verwendet um die Bilder anzuzeigen. In dem ersten Beispiel werden je acht Bilder beider Klassen angezeigt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "images_to_show= np.concatenate((images[labels ==0][:8], images[labels ==1][:8]) ,axis=0)\n",
    "print(len(images_to_show))\n",
    "\n",
    "def plot(images_to_plot, predictions= np.array([]), titles=[]):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(images_to_plot)):\n",
    "        ax = fig.add_subplot(4, 4, 1 + i, xticks=[], yticks=[])\n",
    "        im = images_to_plot[i]\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "        if predictions.size:\n",
    "            ax.set_xlabel('dog: %6.2f \\n muffin %6.2f'\n",
    "                      % (predictions[i][0], predictions[i][1]), fontsize=12)\n",
    "        plt.imshow(im)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot(images_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation\n",
    "Zur Vergrößerung der Datenmenge werden die Images bearbeitet. Für dieses Beispiel werden die Bilder vertikal oder horizontal gespiegelt zusätzlich wird von dem ursprünglichen Bild noch eine Kopie als Grauwertbild erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img= images[0]\n",
    "\n",
    "horizontal_flipt= cv2.flip(img, 0)\n",
    "vertical_flipt= cv2.flip(img, 1)\n",
    "gray_scaled_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "augmented_images= [img, horizontal_flipt, vertical_flipt, gray_scaled_img]\n",
    "titels=['original', 'horizonzal', 'vertical', 'grayscaled']\n",
    "plot(augmented_images, titles=titels)\n",
    "\n",
    "def randomize_images(images,labels):\n",
    "\n",
    "    for index in range(len(images)):\n",
    "        img = images[index]\n",
    "        flipt_img= cv2.flip(img, np.random.randint(0,1))\n",
    "        flipt_img = np.expand_dims(flipt_img, axis=0)\n",
    "        images=np.vstack((images, flipt_img))\n",
    "        labels = np.append(labels, np.asarray(labels[index]))\n",
    "    print(len(images))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach dem vorbereiten der Daten werden die Arrays nach dem Zufallsprinzip durchmischt. Die sklearn.shuffel Methode durchmischt die Bilder und Labels gleichermaßen.Zur Reproduzierbarkeit wird der Random_State auf einen konstanten Wert gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "images , labels = shuffle(images , labels, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend werden die Daten in eine Trainings-, Validierungs- und Teststichprobe aufgeteilt. \n",
    "Trainings und Validierungsstichprobe werden zum anpassen der Gewichte beim Lernen verwendet. \n",
    "Die Teststichprobe muss vor der Trainingsphase abgespalten werden und dient dazu den Klassifikator nach dem Training \n",
    "zu bewerten.\n",
    "<img src=\"Notebook_Images/Test-train-Val.PNG\" height=\"600\" width=\"600\" >\n",
    "<cite data-cite=\"Raschka\">(Sebastian Raschka und Vahid Mirjalili. Machine Learning mit Python\n",
    "und Scikit-learn und TensorFlow: Das umfassende Praxis-Handbuch für\n",
    "Data Science, Deep Learning und Predictive Analytics. 2., aktualisierte\n",
    "und erweiterte Auflage. Frechen: mitp, 2018. isbn: 978-3-95845-733-1.)</cite>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "length=len(labels)\n",
    "\n",
    "X_train = images[:int(length*0.8)]\n",
    "X_val   = images[int(length*0.8):int(length*0.9)]\n",
    "X_test  = images[int(length*0.9):]\n",
    "y_train = labels[:int(length*0.8)] \n",
    "y_val   = labels[int(length*0.8):int(length*0.9)]\n",
    "y_test  = labels[int(length*0.9):]\n",
    "\n",
    "\n",
    "y_train= np_utils.to_categorical(y_train, 2)\n",
    "y_val = np_utils.to_categorical(y_val, 2)\n",
    "\n",
    "print(\"Trainingsdaten:\", X_train.shape)\n",
    "print(\"Validierungsdaten:\", X_val.shape)\n",
    "print(\"Testdaten:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisierung der Pixelwerte\n",
    "Um zu verhindern, dass Ausreißer in den Pixelwerten einen überproportional großen Einfluss bei der Gewichtsänderung haben, werden die Merkmalswerte standartisiert. \n",
    "\n",
    "\\begin{equation*}\n",
    "x^{(i)}_{std}=\\frac{x^{(i)}-\\mu_x}{\\sigma_x}\n",
    "\\end{equation*}\n",
    "\n",
    "<cite data-cite=\"Raschka\">(Sebastian Raschka und Vahid Mirjalili. Machine Learning mit Python\n",
    "und Scikit-learn und TensorFlow: Das umfassende Praxis-Handbuch für\n",
    "Data Science, Deep Learning und Predictive Analytics. 2., aktualisierte\n",
    "und erweiterte Auflage. Frechen: mitp, 2018. isbn: 978-3-95845-733-1.)</cite>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values=np.mean(X_train, axis=0)\n",
    "std_values=np.std(X_train)\n",
    "\n",
    "x_train_centered= (X_train- mean_values)/std_values\n",
    "x_val_centered= (X_val- mean_values)/std_values\n",
    "x_test_centered= (X_test- mean_values)/std_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Mit diesem Befehl wird ein Convolutional-Layer in dem Model erzeugt. Dazu müssen die Anzahl der Filter =32 und die Größe der Filterkerne in Pixel=5x5 sowie die Aktivierungsfunktion activation='relu' angegeben werden. Optional kann die Initalisierung und der Padding Modus angegeben werden.  \n",
    "    * model.add(Convolution2D(32, (5, 5), activation='relu',kernel_initializer='glorot_uniform', padding='same'))\n",
    "\n",
    "Hiermit wird nach einem Convolutional-Layer ein Pooling-Layer der Größe 2x2 Pixel angehangen.\n",
    "    * model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "Dense-Layer sind Vollverknüpfte Schichten. Hier im Beispiel mit 512 Neuronen auf dieser Schicht. Durch die Zahl der Neuronen des letzten Dense-Layer wird die Zahl der zu unterscheidendenden Klassen bestimmt.\n",
    "    * model.add(Dense(512,kernel_initializer='glorot_uniform', activation='relu'))\n",
    "    \n",
    "Zuletzt muss das Model kompiliert werden. In diesem Fall wird als Loss-Funktion Categorical-Crossentropy verwendet, für ein Zweiklassen-Problem kann Binaray-Crossentropy verwendet werden. Als Optimierungsverfahren ist Stochhastical Gradient Descent angegeben, die Parameter wie Lernrate (lr) können während des Lernens variiert werden. \n",
    "    * model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    \n",
    "Der Befehl model.summary gibt die Struktur des Modells in der Console aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D,  BatchNormalization, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (5, 5), activation='relu',kernel_initializer='glorot_uniform', padding='same', \n",
    "                        input_shape=(image_height, image_width, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(32, (3, 3),kernel_initializer='glorot_uniform', activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(32, (3, 3),kernel_initializer='glorot_uniform', activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_initializer='glorot_uniform', activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128,kernel_initializer='glorot_uniform', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Der Fit-Befehl trainiert das Modell. Dazu müssen Training- und Validierungsdaten sowie die Anzahl der Trainingsepochen übergeben werden. Mit dem Verbose Parameter kann bestimmt werden wie oft während des Trainings eine Konsolenausgabe mit aktuellen Trainingswerten stattfinden soll. Callbacks nimmt eine Liste von zuvor definierten Callback-Methoden entgegen, in unserem Fall wurde ein Callback definiert welcher während des Trainings die aktuellen Gewichtungen speichert sobalb die Genauigkeit in einer Epoche gestiegen und der Loss gefallen ist. Es können aber auch Callbacks definiert werden um zum Beispiel bestimmte Werte zur späteren Visualisierung zu speichern oder die Lernrate adaptiv anzupassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='model.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.fit(x_train_centered, y_train,\n",
    "          batch_size=100,\n",
    "          epochs=1,\n",
    "          validation_data=(x_val_centered,  y_val),\n",
    "          verbose=1,\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden eines bereits trainierten Modells\n",
    "Modelle können während und nach dem Lernvorgang zur späteren Wiederverwendung gespeichert werden. Keras bietet hierfür mehrere Formate wie JSON oder hdf5 an. Diese Modelle können anschließend wieder geladen werden um neue Daten zu klassifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(\"myModel.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Die Predict Methode wird verwendet um mit dem Modell die Klassenwahrscheinlichkeiten von Bildern zu bestimmen, dazu können der Methode einzelne Bilder oder ein Array von Bildern übergeben werden. \n",
    "\n",
    "Die Evaluate Methode dient als erste schnelle Methode um ein Modell zu bewerten, den diese Methode bestimmt Genauigkeit und Loss für ein Array an Daten. \n",
    "\n",
    "Zu Beginn wurden die Bilder in Trainings- Validierungs- und Teststichprobe aufgeteilt. Die Teststichprobe kam beim Training nicht zum Einsatz und ist somit für das Modell noch unbekannt. Dadurch kann sie zur Evaluation des Modells dienen.\n",
    "\n",
    "Anschließend werden die Klassenwahrscheinlichkeiten für die eigentlichen Produktivdaten ermittelt. Dazu werden diese zunächst geladen und standardisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_plot= X_test[:16]\n",
    "predictions= model.predict(x_test_centered)[:16]\n",
    "plot(img_to_plot, predictions= predictions)\n",
    "\n",
    "true_labels=np_utils.to_categorical(y_test, 2)\n",
    "metric= model.evaluate(x_test_centered, true_labels)\n",
    "\n",
    "print('loss: %10.2f  \\naccuracy: %6.2f' % (metric[0], metric[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= np.load('test_data.npz')\n",
    "labels=dataset['labels']\n",
    "images=dataset['images']\n",
    "\n",
    "mean_values=np.mean(X_train, axis=0)\n",
    "std_values=np.std(X_train)\n",
    "\n",
    "x_test_centered= (images- mean_values)/std_values\n",
    "plot(images, predictions= model.predict(x_test_centered))\n",
    "\n",
    "true_labels=np_utils.to_categorical(labels, 2)\n",
    "metric= model.evaluate(x_test_centered, true_labels)\n",
    "\n",
    "print('loss: %10.2f  \\naccuracy: %6.2f' % (metric[0], metric[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}